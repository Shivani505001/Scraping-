{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "733e8488-ea8e-42bc-8305-8c6a553a42e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver \n",
    "#from selenium.webdriver.chrome.options import Options\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6478c4cd-8aac-4741-852a-3c24e33dddf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#options = Options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf787b11-fdfc-43b5-9e76-dc42b8dd5cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#url=\"https://coinmarketcap.com/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddeec39e-84bb-43de-b17c-bd516695b246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in d:\\project\\venv\\lib\\site-packages (24.0)\n",
      "Requirement already satisfied: selenium in d:\\project\\venv\\lib\\site-packages (4.21.0)\n",
      "Requirement already satisfied: webdriver-manager in d:\\project\\venv\\lib\\site-packages (4.0.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in d:\\project\\venv\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.1)\n",
      "Requirement already satisfied: trio~=0.17 in d:\\project\\venv\\lib\\site-packages (from selenium) (0.25.1)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in d:\\project\\venv\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in d:\\project\\venv\\lib\\site-packages (from selenium) (2024.6.2)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in d:\\project\\venv\\lib\\site-packages (from selenium) (4.12.1)\n",
      "Requirement already satisfied: requests in d:\\project\\venv\\lib\\site-packages (from webdriver-manager) (2.32.3)\n",
      "Requirement already satisfied: python-dotenv in d:\\project\\venv\\lib\\site-packages (from webdriver-manager) (1.0.1)\n",
      "Requirement already satisfied: packaging in d:\\project\\venv\\lib\\site-packages (from webdriver-manager) (24.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in d:\\project\\venv\\lib\\site-packages (from trio~=0.17->selenium) (23.2.0)\n",
      "Requirement already satisfied: sortedcontainers in d:\\project\\venv\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in d:\\project\\venv\\lib\\site-packages (from trio~=0.17->selenium) (3.7)\n",
      "Requirement already satisfied: outcome in d:\\project\\venv\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in d:\\project\\venv\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in d:\\project\\venv\\lib\\site-packages (from trio~=0.17->selenium) (1.16.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in d:\\project\\venv\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in d:\\project\\venv\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\project\\venv\\lib\\site-packages (from requests->webdriver-manager) (3.3.2)\n",
      "Requirement already satisfied: pycparser in d:\\project\\venv\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.22)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in d:\\project\\venv\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "#driver = webdriver.Chrome(options=options)\n",
    "#try:\n",
    "    #driver.get(url) #HTTP GET request - requests.get(url)\n",
    "    #time.sleep(10)\n",
    "#finally:\n",
    "    #driver.quit()\n",
    "!python.exe -m pip install --upgrade pip\n",
    "!pip install selenium webdriver-manager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5cdaf806-d8bb-4569-96b5-f993a7248a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a19c99-2328-466a-a106-ccd9cfbeef8d",
   "metadata": {},
   "source": [
    "```html\n",
    "<span class=\"sc-d1ede7e3-0 fsQm base-text\">$0.004871</span>\n",
    "<p color=\"red\" data-change=\"down\" font-size=\"1\" data-sensors-click=\"true\" class=\"sc-71024e3e-0 sc-58c82cf9-1 ihXFUo iPawMI\">14.75%&nbsp;(1d)</p>\n",
    "\n",
    "<dd class=\"sc-d1ede7e3-0 hPHvUM base-text\">$46,526,472</dd>\n",
    "\n",
    "//market cap rank\n",
    "<span class=\"text slider-value rank-value\">#665</span>\n",
    "//volume\n",
    "<dd class=\"sc-d1ede7e3-0 hPHvUM base-text\">$13,138,603</dd>\n",
    "//volume_rank\n",
    "<span class=\"text slider-value rank-value\">#377</span>\n",
    "//volume_change\n",
    "<dd class=\"sc-d1ede7e3-0 hPHvUM base-text\">29.32%</dd></div>\n",
    "//circulating_supply\n",
    "<dd class=\"sc-d1ede7e3-0 hPHvUM base-text\">9,663,955,990 DUKO</dd>\n",
    "//total_supply\n",
    "<dd class=\"sc-d1ede7e3-0 hPHvUM base-text\">9,999,609,598 DUKO</dd>\n",
    "//diluted_market_cap\n",
    "<dd class=\"sc-d1ede7e3-0 hPHvUM base-text\">$48,142,454</dd>\n",
    "//contracts \n",
    "//name \n",
    "<span font-weight=\"var(--c-font-weight-400)\" font-size=\"var(--c-font-size-75)\" color=\"text\" data-sensors-click=\"true\" \n",
    "    class=\"sc-71024e3e-0 dEZnuB\">Solana:&nbsp;</span>\n",
    "//address\n",
    "<span font-weight=\"var(--c-font-weight-500)\" font-size=\"var(--c-font-size-75)\" class=\"sc-71024e3e-0 eESYbg address\" color=\"text\" data-sensors-click=\"true\">HLptm5...2G7rf9&nbsp;</span>\n",
    "//websites \n",
    "<span class=\"sc-d1ede7e3-0 fTGacL base-text\" data-role=\"title\">Official links</span>\n",
    "//name\n",
    "<a rel=\"nofollow noopener\" href=\"https://github.com/ethereum/wiki/wiki/White-Paper\" target=\"_blank\">Whitepaper</a>\n",
    "<a rel=\"nofollow noopener\" href=\"https://github.com/ethereum/go-ethereum\" target=\"_blank\">GitHub</a>\n",
    "//social links\n",
    "<span class=\"sc-d1ede7e3-0 fTGacL base-text\" data-role=\"title\">Socials</span>\n",
    "//name\n",
    "<a rel=\"nofollow noopener\" href=\"https://twitter.com/ethereum\" target=\"_blank\">Twitter</a>\n",
    "<a rel=\"nofollow noopener\" href=\"https://reddit.com/r/ethereum\" target=\"_blank\">Reddit</a>\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3df54afc-ad1e-4423-8cae-9fc378ca7668",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "class CoinMarketCapScraper:\n",
    "    def __init__(self, coin):\n",
    "        self.coin = coin\n",
    "        self.url = f\"https://coinmarketcap.com/currencies/{coin}/\"\n",
    "        self.driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "    \n",
    "    def get_coin_data(self):\n",
    "        self.driver.get(self.url)\n",
    "        self.driver.implicitly_wait(10) \n",
    "       \n",
    "        try:\n",
    "            # Wait for the price element to be loaded in the DOM\n",
    "            WebDriverWait(self.driver, 20).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \"span.sc-d1ede7e3-0.fsQm.base-text\"))\n",
    "            )\n",
    "        except Exception as e:\n",
    "            self.driver.quit()\n",
    "            return None\n",
    "        html_content = self.driver.page_source\n",
    "        soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "        data = {}\n",
    "\n",
    "        # Extract price\n",
    "        try:\n",
    "            price_element = soup.select_one('span.sc-d1ede7e3-0.fsQm.base-text')\n",
    "            data['price'] = price_element.text if price_element else None\n",
    "        except Exception as e:\n",
    "            data['price'] = None\n",
    "            \n",
    "         # Extract price change\n",
    "        try:\n",
    "            price_change_element = soup.select_one('p[data-change=\"down\"].sc-71024e3e-0.sc-58c82cf9-1.ihXFUo.iPawMI')\n",
    "            if price_change_element:\n",
    "                # Split the text content by \"%\" and take the first part\n",
    "                price_change_text = price_change_element.text\n",
    "                data['price_change'] = price_change_text.split(\"%\")[0]\n",
    "            else:\n",
    "                data['price_change'] = None\n",
    "        except Exception as e:\n",
    "            data['price_change'] = None\n",
    "            \n",
    "      # Find the market cap rank and volume rank\n",
    "\n",
    "        try:\n",
    "            rank_elements = soup.find_all('span', class_='text slider-value rank-value')\n",
    "            if rank_elements:\n",
    "                data['market_cap_rank'] = rank_elements[0].text.strip()\n",
    "                data['volume_rank'] = rank_elements[1].text.strip() if len(rank_elements) > 1 else None\n",
    "            else:\n",
    "                market_cap_rank = None\n",
    "                volume_rank = None\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while extracting rank values: {e}\")\n",
    "            market_cap_rank = None\n",
    "            volume_rank = None\n",
    "\n",
    "        #volume and market_cap\n",
    "        try:\n",
    "            volume = soup.find_all('dd', class_='sc-d1ede7e3-0 hPHvUM base-text')\n",
    "            if volume:\n",
    "                # Extract the text content of the element\n",
    "                data['market_cap']= volume[0].text.strip().split('%')[1]\n",
    "                data['volume']=volume[1].text.strip().split('%')[1] if len(rank_elements) > 1 else None\n",
    "                data['volume_change']=volume[2].text.strip()\n",
    "                data['circulating_supply']=volume[3].text.strip()\n",
    "                data['total_supply']=volume[5].text.strip()\n",
    "                data['diluted_market_cap']=volume[6].text.strip()\n",
    "            else:\n",
    "                data['volume'] = None\n",
    "                data['market_cap'] = None\n",
    "                data['volume_change']=None\n",
    "                data['circulating_supply']=None\n",
    "                data['total_supply']=None\n",
    "                data['diluted_market_cap']=None\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while extracting rank values: {e}\")\n",
    "            data['volume'] = None\n",
    "            data['market_cap'] = None\n",
    "            data['volume_change']=None\n",
    "            data['circulating_supply']=None\n",
    "            data['total_supply']=None\n",
    "            data['diluted_market_cap']=None\n",
    "        #extract contracts \n",
    "        try:\n",
    "            contracts_elements = soup.find_all('span', class_='sc-71024e3e-0 dEZnuB')\n",
    "            addresses_elements = soup.find_all('span', class_='sc-71024e3e-0 eESYbg address')\n",
    "    \n",
    "            contracts = []\n",
    "            for contract_element, address_element in zip(contracts_elements, addresses_elements):\n",
    "                name = contract_element.text.strip().split(':')[0]  # Extract the name\n",
    "                address = address_element.text.strip()             # Extract the address\n",
    "                contracts.append({'name': name, 'address': address})\n",
    "\n",
    "            data['contracts'] = contracts\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while extracting contract values: {e}\")\n",
    "            data['contracts'] = []\n",
    "    \n",
    "        \n",
    "        # Extract official links and socials\n",
    "        try:\n",
    "            links_section_elements = soup.find_all('div', class_='sc-d1ede7e3-0 jTYLCR')\n",
    "        \n",
    "            for section_element in links_section_elements:\n",
    "                # Check if the section contains official links or socials\n",
    "                title_element = section_element.find('span', class_='base-text', attrs={'data-role': 'title'})\n",
    "                if title_element:\n",
    "                    section_title = title_element.text.strip()\n",
    "                    if section_title == 'Official links':\n",
    "                        # Extract official links\n",
    "                        official_links_elements = section_element.find_all('a', rel='nofollow noopener', target='_blank')\n",
    "                        official_links = [{'name': link.text.strip(), 'link': link['href']} for link in official_links_elements]\n",
    "                        data['official_links'] = official_links\n",
    "                    elif section_title == 'Socials':\n",
    "                        # Extract socials\n",
    "                        socials_elements = section_element.find_all('a', rel='nofollow noopener', target='_blank')\n",
    "                        socials = [{'name': social.text.strip(), 'url': social['href']} for social in socials_elements]\n",
    "                        data['socials'] = socials\n",
    "        except Exception as e:\n",
    "            data['official_links'] = []\n",
    "            data['socials'] = []\n",
    "        return data\n",
    "        \n",
    "    def close(self):\n",
    "        self.driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1d7bbc22-f9db-490b-bc72-18ffd9b14948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'price': '$3,684.95', 'price_change': '3.33', 'market_cap_rank': '#2', 'volume_rank': '#3', 'market_cap': '$442,710,548,093', 'volume': '$16,465,467,133', 'volume_change': '3.72%', 'circulating_supply': '120,147,950 ETH', 'total_supply': '‚àû', 'diluted_market_cap': '$442,710,548,093', 'contracts': [{'name': 'BNB Smart Chain (BEP20)', 'address': '0x2170...f933f8'}], 'official_links': [{'name': 'Whitepaper', 'link': 'https://github.com/ethereum/wiki/wiki/White-Paper'}, {'name': 'GitHub', 'link': 'https://github.com/ethereum/go-ethereum'}], 'socials': [{'name': 'ùïèTwitter', 'url': 'https://twitter.com/ethereum'}, {'name': 'Reddit', 'url': 'https://reddit.com/r/ethereum'}, {'name': 'Chat', 'url': 'https://gitter.im/orgs/ethereum/rooms'}]}\n"
     ]
    }
   ],
   "source": [
    "scraper = CoinMarketCapScraper('Ethereum')\n",
    "data = scraper.get_coin_data()\n",
    "scraper.close()\n",
    "print(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "433f679d-49cb-49fc-bf39-4c96aca840ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook coinmarketcap.ipynb to script\n",
      "[NbConvertApp] Writing 8865 bytes to coinmarketcap.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script coinmarketcap.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df286f6-8185-43b3-9171-ada633c43bdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
